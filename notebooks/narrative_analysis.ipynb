{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809a4f86-e222-4843-b588-78f00e7c600e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1a311-0af0-42c7-a3ec-ff54f19057ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The Narrative Analysis tool should now be fully functional, allowing you to:\n",
    "\n",
    "Upload JSON files containing narrative text\n",
    "Analyze the narrative structure (timeline, plotline, and storyline)\n",
    "Visualize the results with interactive charts\n",
    "Generate and download a comprehensive PDF report\n",
    "\n",
    "The GUI will:\n",
    "Validate JSON format and provide specific error messages\n",
    "Check if the JSON contains actual narrative text\n",
    "Provide more detailed feedback at each step of the analysis\n",
    "Include a help button that explains the expected file format with examples\n",
    "The tool should be user-friendly and help users understand what went wrong if they upload an incorrect file format.\n",
    "\n",
    "If you want to test it with a sample narrative, you can create a simple JSON file with this structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2cc26-3eae-4a8b-986d-7f94432bb071",
   "metadata": {},
   "source": [
    "{\n",
    "  \"title\": \"The Three Little Pigs\",\n",
    "  \"text\": \"Once upon a time, there were three little pigs. The first pig built a house of straw. The second pig built a house of sticks. The third pig built a house of bricks. One day, a big bad wolf came to the first pig's house. He huffed and puffed and blew the house down. The first pig ran to the second pig's house. The wolf followed and blew down the second house too. Both pigs ran to the third pig's house. The wolf tried to blow down the brick house, but he couldn't. He tried to enter through the chimney, but the third pig had a pot of boiling water. The wolf fell into the water and ran away. The three pigs lived happily ever after.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc4422-db38-404a-b05e-7b6163edab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "required_packages = ['pandas', 'numpy', 'matplotlib', 'seaborn', 'networkx', \n",
    "                    'ipywidgets', 'nltk', 'spacy', 'fpdf', 'pillow']\n",
    "\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = [pkg for pkg in required_packages if pkg.lower() not in installed]\n",
    "\n",
    "if missing:\n",
    "    print(f\"Installing missing packages: {missing}\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + missing)\n",
    "    \n",
    "    # Install spacy model separately\n",
    "    if 'spacy' in missing:\n",
    "        subprocess.check_call([sys.executable, '-m', 'spacy', 'download', 'en_core_web_sm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "476df855-cbed-4894-aaa7-109c1b6f6e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\lissa\\AppData\\Local\\Temp\\pip-uninstall-3xkekney'."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 51.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 45.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 36.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\lissa\\miniconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635cb38-f6cb-459a-8ccf-c67910a7c782",
   "metadata": {},
   "source": [
    "First, let's run the imports and setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e913e0-6319-40a4-8b27-e57b0bdc9b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lissa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lissa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lissa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now import all required packages\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output, FileLink\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import re\n",
    "from datetime import datetime\n",
    "import io\n",
    "from fpdf import FPDF\n",
    "import base64\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    import sys\n",
    "    !{sys.executable} -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81d7d7-6c4f-44da-a475-746162a54d3b",
   "metadata": {},
   "source": [
    "Now, let's define the NarrativeAnalyzer class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b0c5cb-f1b9-46d8-979e-781dff9c8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrativeAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.text = \"\"\n",
    "        self.sentences = []\n",
    "        self.processed_text = \"\"\n",
    "        self.events = []\n",
    "        self.timeline = []\n",
    "        self.plotline = {}\n",
    "        self.storyline = {}\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def load_data(self, file_content):\n",
    "        \"\"\"Load text data from JSON content\"\"\"\n",
    "        try:\n",
    "            data = json.loads(file_content)\n",
    "            \n",
    "            # Handle different JSON structures\n",
    "            if isinstance(data, dict):\n",
    "                if 'text' in data:\n",
    "                    self.text = data['text']\n",
    "                elif 'content' in data:\n",
    "                    self.text = data['content']\n",
    "                else:\n",
    "                    # Use the first string value found\n",
    "                    text_found = False\n",
    "                    for key, value in data.items():\n",
    "                        if isinstance(value, str) and len(value) > 100:  # Assuming text is reasonably long\n",
    "                            self.text = value\n",
    "                            text_found = True\n",
    "                            break\n",
    "                    \n",
    "                    if not text_found:\n",
    "                        raise ValueError(\"No text field found in JSON. Expected 'text' or 'content' field.\")\n",
    "            elif isinstance(data, list):\n",
    "                # Concatenate all string items or text fields\n",
    "                text_parts = []\n",
    "                for item in data:\n",
    "                    if isinstance(item, str):\n",
    "                        text_parts.append(item)\n",
    "                    elif isinstance(item, dict) and ('text' in item or 'content' in item):\n",
    "                        text_parts.append(item.get('text', item.get('content', '')))\n",
    "                self.text = ' '.join(text_parts)\n",
    "                \n",
    "                if not text_parts:\n",
    "                    raise ValueError(\"No text content found in JSON array. Expected strings or objects with 'text' field.\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected JSON structure. Expected object or array, got {type(data).__name__}.\")\n",
    "            \n",
    "            if not self.text:\n",
    "                raise ValueError(\"No text content found in the JSON file\")\n",
    "                \n",
    "            return True\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            return False\n",
    "        except ValueError as e:\n",
    "            print(f\"Data error: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            return False\n",
    "       \n",
    "    \n",
    "    def preprocess_text(self):\n",
    "        \"\"\"Preprocess the text for NLP analysis\"\"\"\n",
    "        if not self.text:\n",
    "            return False\n",
    "        \n",
    "        # Tokenize into sentences\n",
    "        self.sentences = sent_tokenize(self.text)\n",
    "        \n",
    "        # Process each sentence\n",
    "        processed_sentences = []\n",
    "        for sentence in self.sentences:\n",
    "            # Tokenize words\n",
    "            words = word_tokenize(sentence)\n",
    "            \n",
    "            # Remove stopwords and lemmatize\n",
    "            filtered_words = [self.lemmatizer.lemmatize(word.lower()) \n",
    "                             for word in words \n",
    "                             if word.lower() not in self.stop_words and word.isalnum()]\n",
    "            \n",
    "            processed_sentences.append(' '.join(filtered_words))\n",
    "        \n",
    "        self.processed_text = ' '.join(processed_sentences)\n",
    "        return True\n",
    "    \n",
    "    def extract_events(self):\n",
    "        \"\"\"Extract events from the text using spaCy\"\"\"\n",
    "        if not self.sentences:\n",
    "            return False\n",
    "        \n",
    "        self.events = []\n",
    "        for i, sentence in enumerate(self.sentences):\n",
    "            doc = nlp(sentence)\n",
    "            \n",
    "            # Extract events (verbs and their arguments)\n",
    "            for token in doc:\n",
    "                if token.pos_ == \"VERB\":\n",
    "                    # Get subject\n",
    "                    subjects = [subj.text for subj in token.head.children if subj.dep_ in (\"nsubj\", \"nsubjpass\")]\n",
    "                    subject = subjects[0] if subjects else \"\"\n",
    "                    \n",
    "                    # Get object\n",
    "                    objects = [obj.text for obj in token.children if obj.dep_ in (\"dobj\", \"pobj\")]\n",
    "                    obj = objects[0] if objects else \"\"\n",
    "                    \n",
    "                    # Get time expressions\n",
    "                    time_entities = [ent.text for ent in doc.ents if ent.label_ in (\"DATE\", \"TIME\")]\n",
    "                    time = time_entities[0] if time_entities else \"\"\n",
    "                    \n",
    "                    # Create event\n",
    "                    event = {\n",
    "                        \"sentence_id\": i,\n",
    "                        \"sentence\": sentence,\n",
    "                        \"verb\": token.text,\n",
    "                        \"subject\": subject,\n",
    "                        \"object\": obj,\n",
    "                        \"time\": time\n",
    "                    }\n",
    "                    self.events.append(event)\n",
    "        \n",
    "        return len(self.events) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f45a9-c331-4e9f-919b-8a6bcea24412",
   "metadata": {},
   "source": [
    "Let's continue with the analysis methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efabd9fc-d8b8-4c97-910e-d584d2d61ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def analyze_timeline(self):\n",
    "        \"\"\"Analyze the timeline of events\"\"\"\n",
    "        if not self.events:\n",
    "            return False\n",
    "        \n",
    "        # Sort events by sentence_id to maintain chronological order\n",
    "        sorted_events = sorted(self.events, key=lambda x: x[\"sentence_id\"])\n",
    "        \n",
    "        # Create timeline\n",
    "        self.timeline = []\n",
    "        for event in sorted_events:\n",
    "            timeline_event = {\n",
    "                \"event\": f\"{event['subject']} {event['verb']} {event['object']}\".strip(),\n",
    "                \"time\": event[\"time\"] if event[\"time\"] else \"Unspecified\",\n",
    "                \"sentence\": event[\"sentence\"]\n",
    "            }\n",
    "            self.timeline.append(timeline_event)\n",
    "        \n",
    "        return len(self.timeline) > 0\n",
    "    \n",
    "    def analyze_plotline(self):\n",
    "        \"\"\"Analyze the plotline using Vossen's framework\"\"\"\n",
    "        if not self.events:\n",
    "            return False\n",
    "        \n",
    "        # Initialize plotline components\n",
    "        self.plotline = {\n",
    "            \"exposition\": [],\n",
    "            \"rising_action\": [],\n",
    "            \"climax\": [],\n",
    "            \"falling_action\": [],\n",
    "            \"resolution\": []\n",
    "        }\n",
    "        \n",
    "        # Simple heuristic: divide events into 5 parts\n",
    "        total_events = len(self.events)\n",
    "        section_size = max(1, total_events // 5)\n",
    "        \n",
    "        # Assign events to plotline components\n",
    "        for i, event in enumerate(self.events):\n",
    "            event_summary = f\"{event['subject']} {event['verb']} {event['object']}\".strip()\n",
    "            \n",
    "            if i < section_size:\n",
    "                self.plotline[\"exposition\"].append(event_summary)\n",
    "            elif i < section_size * 2:\n",
    "                self.plotline[\"rising_action\"].append(event_summary)\n",
    "            elif i < section_size * 3:\n",
    "                self.plotline[\"climax\"].append(event_summary)\n",
    "            elif i < section_size * 4:\n",
    "                self.plotline[\"falling_action\"].append(event_summary)\n",
    "            else:\n",
    "                self.plotline[\"resolution\"].append(event_summary)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def analyze_storyline(self):\n",
    "        \"\"\"Analyze the storyline using narratology frameworks\"\"\"\n",
    "        if not self.events:\n",
    "            return False\n",
    "        \n",
    "        # Initialize storyline components based on Caselli and Segers' framework\n",
    "        self.storyline = {\n",
    "            \"characters\": {},\n",
    "            \"settings\": [],\n",
    "            \"conflicts\": [],\n",
    "            \"themes\": [],\n",
    "            \"narrative_arcs\": []\n",
    "        }\n",
    "        \n",
    "        # Extract characters (subjects and objects)\n",
    "        characters = {}\n",
    "        for event in self.events:\n",
    "            if event[\"subject\"] and len(event[\"subject\"]) > 1:\n",
    "                if event[\"subject\"] not in characters:\n",
    "                    characters[event[\"subject\"]] = {\"actions\": [], \"mentions\": 0}\n",
    "                characters[event[\"subject\"]][\"mentions\"] += 1\n",
    "                characters[event[\"subject\"]][\"actions\"].append(event[\"verb\"])\n",
    "            \n",
    "            if event[\"object\"] and len(event[\"object\"]) > 1:\n",
    "                if event[\"object\"] not in characters:\n",
    "                    characters[event[\"object\"]] = {\"actions\": [], \"mentions\": 0}\n",
    "                characters[event[\"object\"]][\"mentions\"] += 1\n",
    "        \n",
    "        # Keep only significant characters (mentioned more than once)\n",
    "        self.storyline[\"characters\"] = {k: v for k, v in characters.items() if v[\"mentions\"] > 1}\n",
    "        \n",
    "        # Extract settings (time expressions)\n",
    "        settings = set()\n",
    "        for event in self.events:\n",
    "            if event[\"time\"]:\n",
    "                settings.add(event[\"time\"])\n",
    "        self.storyline[\"settings\"] = list(settings)\n",
    "        \n",
    "        # Simple conflict detection (negative verbs or emotional content)\n",
    "        conflict_verbs = [\"fight\", \"argue\", \"disagree\", \"oppose\", \"conflict\", \"battle\", \"struggle\"]\n",
    "        for event in self.events:\n",
    "            for conflict_verb in conflict_verbs:\n",
    "                if conflict_verb in event[\"verb\"].lower():\n",
    "                    self.storyline[\"conflicts\"].append(\n",
    "                        f\"{event['subject']} {event['verb']} {event['object']}\".strip()\n",
    "                    )\n",
    "        \n",
    "        # Identify themes (most common verbs)\n",
    "        all_verbs = [event[\"verb\"].lower() for event in self.events]\n",
    "        verb_freq = {}\n",
    "        for verb in all_verbs:\n",
    "            if verb not in verb_freq:\n",
    "                verb_freq[verb] = 0\n",
    "            verb_freq[verb] += 1\n",
    "        \n",
    "        # Top 5 verbs as themes\n",
    "        top_verbs = sorted(verb_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        self.storyline[\"themes\"] = [verb for verb, freq in top_verbs]\n",
    "        \n",
    "        # Narrative arcs (simplified)\n",
    "        self.storyline[\"narrative_arcs\"] = [\n",
    "            \"Introduction of characters\",\n",
    "            \"Setting establishment\",\n",
    "            \"Conflict development\",\n",
    "            \"Rising tension\",\n",
    "            \"Resolution\"\n",
    "        ]\n",
    "        \n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583746f-b299-4eb5-974a-1931c2a9f238",
   "metadata": {},
   "source": [
    "Now, let's add the visualization methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317c25ce-abab-4b9a-908c-ada3ac2c0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def visualize_timeline(self):\n",
    "        \"\"\"Create a visualization of the timeline\"\"\"\n",
    "        if not self.timeline:\n",
    "            return None\n",
    "        \n",
    "        # Create a DataFrame for the timeline\n",
    "        df = pd.DataFrame(self.timeline)\n",
    "        \n",
    "        # Create a figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot events on a timeline\n",
    "        for i, event in enumerate(self.timeline):\n",
    "            plt.scatter(i, 1, s=100, color='blue')\n",
    "            plt.text(i, 1.1, event[\"event\"], rotation=45, ha='right', fontsize=8)\n",
    "        \n",
    "        plt.yticks([])\n",
    "        plt.xlabel('Event Sequence')\n",
    "        plt.title('Narrative Timeline')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure to a bytes buffer\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        return buf\n",
    "    \n",
    "    def visualize_plotline(self):\n",
    "        \"\"\"Create a visualization of the plotline\"\"\"\n",
    "        if not self.plotline:\n",
    "            return None\n",
    "        \n",
    "        # Count events in each plot component\n",
    "        plot_counts = {k: len(v) for k, v in self.plotline.items()}\n",
    "        \n",
    "        # Create a figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot the arc\n",
    "        x = np.arange(len(plot_counts))\n",
    "        y = [plot_counts[\"exposition\"], \n",
    "             plot_counts[\"rising_action\"], \n",
    "             plot_counts[\"climax\"],\n",
    "             plot_counts[\"falling_action\"], \n",
    "             plot_counts[\"resolution\"]]\n",
    "        \n",
    "        # Create a smooth curve\n",
    "        x_smooth = np.linspace(0, len(x)-1, 100)\n",
    "        y_smooth = np.interp(x_smooth, x, y)\n",
    "        \n",
    "        plt.plot(x_smooth, y_smooth, 'b-', linewidth=2)\n",
    "        plt.fill_between(x_smooth, y_smooth, alpha=0.3)\n",
    "        \n",
    "        plt.xticks(x, list(plot_counts.keys()), rotation=45)\n",
    "        plt.ylabel('Number of Events')\n",
    "        plt.title('Narrative Plot Structure')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure to a bytes buffer\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        return buf\n",
    "    \n",
    "    def visualize_storyline(self):\n",
    "        \"\"\"Create a visualization of the storyline\"\"\"\n",
    "        if not self.storyline or not self.storyline[\"characters\"]:\n",
    "            return None\n",
    "        \n",
    "        # Create a character network\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add character nodes\n",
    "        for character in self.storyline[\"characters\"]:\n",
    "            G.add_node(character, size=self.storyline[\"characters\"][character][\"mentions\"] * 100)\n",
    "        \n",
    "        # Add edges between characters that appear in the same events\n",
    "        character_pairs = []\n",
    "        for event in self.events:\n",
    "            if event[\"subject\"] in self.storyline[\"characters\"] and event[\"object\"] in self.storyline[\"characters\"]:\n",
    "                character_pairs.append((event[\"subject\"], event[\"object\"]))\n",
    "        \n",
    "        # Count frequency of character interactions\n",
    "        edge_weights = {}\n",
    "        for pair in character_pairs:\n",
    "            if pair not in edge_weights:\n",
    "                edge_weights[pair] = 0\n",
    "            edge_weights[pair] += 1\n",
    "        \n",
    "        # Add weighted edges\n",
    "        for pair, weight in edge_weights.items():\n",
    "            G.add_edge(pair[0], pair[1], weight=weight)\n",
    "        \n",
    "        # Create a figure\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Get node sizes\n",
    "        node_sizes = [G.nodes[node]['size'] for node in G.nodes]\n",
    "        \n",
    "        # Get edge weights\n",
    "        edge_weights = [G.edges[edge]['weight'] for edge in G.edges]\n",
    "        \n",
    "        # Draw the network\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='lightblue')\n",
    "        nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.7)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "        \n",
    "        plt.title('Character Relationship Network')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure to a bytes buffer\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        return buf\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate a PDF report of the analysis\"\"\"\n",
    "        # Create a PDF\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        \n",
    "        # Set font\n",
    "        pdf.set_font(\"Arial\", \"B\", 16)\n",
    "        pdf.cell(0, 10, \"Computational Narrative Analysis Report\", ln=True, align=\"C\")\n",
    "        pdf.ln(10)\n",
    "        \n",
    "        # Add timeline analysis\n",
    "        pdf.set_font(\"Arial\", \"B\", 14)\n",
    "        pdf.cell(0, 10, \"1. Timeline Event Analysis\", ln=True)\n",
    "        pdf.set_font(\"Arial\", \"\", 12)\n",
    "        pdf.multi_cell(0, 10, \"The timeline analysis identifies key events in chronological order, showing how the narrative unfolds over time.\")\n",
    "        \n",
    "        # Add timeline events\n",
    "        pdf.set_font(\"Arial\", \"I\", 12)\n",
    "        for i, event in enumerate(self.timeline[:10]):  # Limit to first 10 events\n",
    "            pdf.multi_cell(0, 10, f\"{i+1}. {event['event']} ({event['time']})\")\n",
    "        \n",
    "        # Add timeline visualization\n",
    "        timeline_img = self.visualize_timeline()\n",
    "        if timeline_img:\n",
    "            # Save the image temporarily\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:\n",
    "                tmp_name = tmp.name\n",
    "                img = Image.open(timeline_img)\n",
    "                img.save(tmp_name)\n",
    "            \n",
    "            # Add image to PDF\n",
    "            pdf.add_page()\n",
    "            pdf.image(tmp_name, x=10, y=30, w=180)\n",
    "            pdf.ln(120)  # Space for the image\n",
    "            \n",
    "            # Clean up\n",
    "            os.unlink(tmp_name)\n",
    "        \n",
    "        # Add plotline analysis\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", \"B\", 14)\n",
    "        pdf.cell(0, 10, \"2. Plotline Analysis\", ln=True)\n",
    "        pdf.set_font(\"Arial\", \"\", 12)\n",
    "        pdf.multi_cell(0, 10, \"The plotline analysis breaks down the narrative into the traditional five-act structure based on Vossen's framework.\")\n",
    "        \n",
    "        # Add plotline components\n",
    "        for component, events in self.plotline.items():\n",
    "            pdf.set_font(\"Arial\", \"B\", 12)\n",
    "            pdf.cell(0, 10, f\"{component.replace('_', ' ').title()}:\", ln=True)\n",
    "            pdf.set_font(\"Arial\", \"\", 12)\n",
    "            for i, event in enumerate(events[:3]):  # Limit to first 3 events per component\n",
    "                pdf.multi_cell(0, 10, f\"- {event}\")\n",
    "        \n",
    "        # Add plotline visualization\n",
    "        plotline_img = self.visualize_plotline()\n",
    "        if plotline_img:\n",
    "            # Save the image temporarily\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:\n",
    "                tmp_name = tmp.name\n",
    "                img = Image.open(plotline_img)\n",
    "                img.save(tmp_name)\n",
    "            \n",
    "            # Add image to PDF\n",
    "            pdf.add_page()\n",
    "            pdf.image(tmp_name, x=10, y=30, w=180)\n",
    "            pdf.ln(120)  # Space for the image\n",
    "            \n",
    "            # Clean up\n",
    "            os.unlink(tmp_name)\n",
    "        \n",
    "        # Add storyline analysis\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", \"B\", 14)\n",
    "        pdf.cell(0, 10, \"3. Storyline Analysis\", ln=True)\n",
    "        pdf.set_font(\"Arial\", \"\", 12)\n",
    "        pdf.multi_cell(0, 10, \"The storyline analysis examines characters, settings, conflicts, themes, and narrative arcs based on Caselli and Segers' narratology framework.\")\n",
    "        \n",
    "        # Add characters\n",
    "        pdf.set_font(\"Arial\", \"B\", 12)\n",
    "        pdf.cell(0, 10, \"Characters:\", ln=True)\n",
    "        pdf.set_font(\"Arial\", \"\", 12)\n",
    "        for character, info in list(self.storyline[\"characters\"].items())[:5]:  # Limit to first 5 characters\n",
    "            pdf.multi_cell(0, 10, f\"- {character}: mentioned {info['mentions']} times\")\n",
    "        \n",
    "        # Add settings\n",
    "        pdf.set_font(\"Arial\", \"B\", 12)\n",
    "        pdf.cell(0, 10, \"Settings:\", ln=True)\n",
    "        pdf.set_font(\"Arial\", \"\", 12)\n",
    "        for setting in self.storyline[\"settings\"][:5]:  # Limit to first 5 settings\n",
    "            pdf.multi_cell(0, 10, f\"- {setting}\")\n",
    "        \n",
    "        # Add themes\n",
    "        pdf.set_font(\"Arial\", \"B\", 12)\n",
    "        pdf.cell(0, 10, \"Themes:\", ln=True)\n",
    "        pdf.set_font(\"Arial\", \"\", 12)\n",
    "        for theme in self.storyline[\"themes\"]:\n",
    "            pdf.multi_cell(0, 10, f\"- {theme}\")\n",
    "        \n",
    "        # Add storyline visualization\n",
    "        storyline_img = self.visualize_storyline()\n",
    "        if storyline_img:\n",
    "            # Save the image temporarily\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:\n",
    "                tmp_name = tmp.name\n",
    "                img = Image.open(storyline_img)\n",
    "                img.save(tmp_name)\n",
    "            \n",
    "            # Add image to PDF\n",
    "            pdf.add_page()\n",
    "            pdf.image(tmp_name, x=10, y=30, w=180)\n",
    "            pdf.ln(120)  # Space for the image\n",
    "            \n",
    "            # Clean up\n",
    "            os.unlink(tmp_name)\n",
    "        \n",
    "        # Create a temporary file to save the PDF\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp:\n",
    "            tmp_name = tmp.name\n",
    "            pdf.output(tmp_name)\n",
    "        \n",
    "        return tmp_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c18636-3596-419f-812c-14199b0da498",
   "metadata": {},
   "source": [
    "Now, let's implement the GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a423eb08-d4fc-4dbc-bd40-fd09b987a6d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4889858de487452d8a3a73ec66a27e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h1>Computational Narrative Analysis</h1><p>Upload a JSON file containing narrative text for analy…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557ada7caf0341babcb91d1ec9a5a471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value=(), accept='.json', description='Upload JSON:', layout=Layout(width='300px')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce572f652a940c4921a8ba0f8cf2374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc51406150747f2bc259f89fbe952f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3ba1899d9e46bab8735b641eb816a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output()), selected_index=0, titles=('Timeline', 'Plotline', 'Storyline'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231ffb403d6f4f82930c40f9126aedac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the GUI for the application\n",
    "# Create an updated GUI function with help button and improved error handling\n",
    "def create_narrative_analysis_gui():\n",
    "    # Create the analyzer\n",
    "    analyzer = NarrativeAnalyzer()\n",
    "    \n",
    "    # Create widgets\n",
    "    header = widgets.HTML(\n",
    "        value=\"<h1>Computational Narrative Analysis</h1>\"\n",
    "              \"<p>Upload a JSON file containing narrative text for analysis.</p>\"\n",
    "    )\n",
    "    \n",
    "    file_upload = widgets.FileUpload(\n",
    "        accept='.json',\n",
    "        multiple=False,\n",
    "        description='Upload JSON:',\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    analyze_button = widgets.Button(\n",
    "        description='Analyze Text',\n",
    "        button_style='primary',\n",
    "        disabled=True,\n",
    "        layout=widgets.Layout(width='150px')\n",
    "    )\n",
    "    \n",
    "    download_button = widgets.Button(\n",
    "        description='Download Report',\n",
    "        button_style='success',\n",
    "        disabled=True,\n",
    "        layout=widgets.Layout(width='150px')\n",
    "    )\n",
    "    \n",
    "    # Add help button\n",
    "    help_button = widgets.Button(\n",
    "        description='Help',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "    \n",
    "    status_output = widgets.Output()\n",
    "    help_output = widgets.Output()\n",
    "    result_output = widgets.Output()\n",
    "    \n",
    "    # Create tabs for different analyses\n",
    "    tab_titles = ['Timeline', 'Plotline', 'Storyline']\n",
    "    children = [widgets.Output() for _ in range(len(tab_titles))]\n",
    "    tab = widgets.Tab()\n",
    "    tab.children = children\n",
    "    for i in range(len(tab_titles)):\n",
    "        tab.set_title(i, tab_titles[i])\n",
    "    \n",
    "    # Define callback functions\n",
    "    def on_file_upload_change(change):\n",
    "        if file_upload.value:\n",
    "            analyze_button.disabled = False\n",
    "        else:\n",
    "            analyze_button.disabled = True\n",
    "    \n",
    "    def on_analyze_button_click(b):\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(\"Analyzing text...\")\n",
    "        logging.info(\"status output cleared\")\n",
    "        \n",
    "        # Clear previous results\n",
    "        for child in tab.children:\n",
    "            with child:\n",
    "                clear_output()\n",
    "        logging.info(\"tab output cleared\")\n",
    "        \n",
    "        \n",
    "        with result_output:\n",
    "            clear_output()\n",
    "        logging.info(\"results output cleared\")\n",
    "        \n",
    "        \n",
    "        # Get file content\n",
    "        logging.info(file_upload.value)\n",
    "        logging.info(file_upload.value[0])\n",
    "        file_content = str(next(iter(file_upload.value[0].content.tobytes())))\n",
    "        logging.info(type(file_content))\n",
    "        logging.info(file_content)\n",
    "        \n",
    "        \n",
    "        # Validate JSON format first\n",
    "        try:\n",
    "            json.loads(file_content)\n",
    "            logging.info(\"json loaded\")\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            with status_output:\n",
    "                clear_output()\n",
    "                print(f\"❌ Error: Invalid JSON format. Please check your file.\")\n",
    "                print(f\"Details: {str(e)}\")\n",
    "                print(\"\\nExpected format examples:\")\n",
    "                print('{\"text\": \"Your narrative text here...\"}')\n",
    "                print('{\"content\": \"Your narrative text here...\"}')\n",
    "                print('{\"title\": \"Story Title\", \"text\": \"Your narrative text here...\"}')\n",
    "            return\n",
    "        \n",
    "        # Load and analyze the data\n",
    "        with status_output:\n",
    "            if analyzer.load_data(file_content):\n",
    "                print(\"✅ Data loaded successfully.\")\n",
    "                \n",
    "                # Check if text was actually found in the JSON\n",
    "                if not analyzer.text or len(analyzer.text) < 50:  # Arbitrary minimum length\n",
    "                    clear_output()\n",
    "                    print(\"❌ Error: No substantial text content found in the JSON file.\")\n",
    "                    print(\"\\nYour JSON file should contain a text field with narrative content.\")\n",
    "                    print(\"Expected format examples:\")\n",
    "                    print('{\"text\": \"Once upon a time...\"}')\n",
    "                    print('{\"content\": \"Once upon a time...\"}')\n",
    "                    return\n",
    "                    \n",
    "                if analyzer.preprocess_text():\n",
    "                    print(\"✅ Text preprocessed successfully.\")\n",
    "                    \n",
    "                    if analyzer.extract_events():\n",
    "                        print(f\"✅ Extracted {len(analyzer.events)} events.\")\n",
    "                        \n",
    "                        if analyzer.analyze_timeline():\n",
    "                            print(\"✅ Timeline analysis complete.\")\n",
    "                            \n",
    "                            if analyzer.analyze_plotline():\n",
    "                                print(\"✅ Plotline analysis complete.\")\n",
    "                                \n",
    "                                if analyzer.analyze_storyline():\n",
    "                                    print(\"✅ Storyline analysis complete.\")\n",
    "                                    download_button.disabled = False\n",
    "                                else:\n",
    "                                    print(\"❌ Error: Storyline analysis failed. The narrative may not have clear character relationships.\")\n",
    "                            else:\n",
    "                                print(\"❌ Error: Plotline analysis failed. The narrative may not have enough events to form a plot structure.\")\n",
    "                        else:\n",
    "                            print(\"❌ Error: Timeline analysis failed. The narrative may not have a clear sequence of events.\")\n",
    "                    else:\n",
    "                        print(\"❌ Error: No events extracted from the text. The narrative may not contain identifiable actions or events.\")\n",
    "                else:\n",
    "                    print(\"❌ Error: Text preprocessing failed. The text may be too short or in an unsupported format.\")\n",
    "            else:\n",
    "                print(\"❌ Error: Failed to load data from the JSON file.\")\n",
    "                print(\"\\nPlease ensure your JSON file contains narrative text in one of these formats:\")\n",
    "                print('{\"text\": \"Your narrative text here...\"}')\n",
    "                print('{\"content\": \"Your narrative text here...\"}')\n",
    "                print('{\"title\": \"Story Title\", \"text\": \"Your narrative text here...\"}')\n",
    "        \n",
    "        # Display results in tabs\n",
    "        # Timeline tab\n",
    "        with tab.children[0]:\n",
    "            if analyzer.timeline:\n",
    "                # Display timeline visualization\n",
    "                timeline_img = analyzer.visualize_timeline()\n",
    "                if timeline_img:\n",
    "                    display(HTML(\"<h3>Timeline Visualization</h3>\"))\n",
    "                    display(Image.open(timeline_img))\n",
    "                \n",
    "                # Display timeline events\n",
    "                display(HTML(\"<h3>Timeline Events</h3>\"))\n",
    "                timeline_df = pd.DataFrame(analyzer.timeline)\n",
    "                display(timeline_df[['event', 'time']])\n",
    "            else:\n",
    "                display(HTML(\"<p>No timeline data available.</p>\"))\n",
    "        \n",
    "        # Plotline tab\n",
    "        with tab.children[1]:\n",
    "            if analyzer.plotline:\n",
    "                # Display plotline visualization\n",
    "                plotline_img = analyzer.visualize_plotline()\n",
    "                if plotline_img:\n",
    "                    display(HTML(\"<h3>Plotline Visualization</h3>\"))\n",
    "                    display(Image.open(plotline_img))\n",
    "                \n",
    "                # Display plotline components\n",
    "                display(HTML(\"<h3>Plotline Components</h3>\"))\n",
    "                for component, events in analyzer.plotline.items():\n",
    "                    display(HTML(f\"<h4>{component.replace('_', ' ').title()}</h4>\"))\n",
    "                    for event in events[:5]:  # Limit to first 5 events\n",
    "                        display(HTML(f\"<p>- {event}</p>\"))\n",
    "            else:\n",
    "                display(HTML(\"<p>No plotline data available.</p>\"))\n",
    "        \n",
    "        # Storyline tab\n",
    "        with tab.children[2]:\n",
    "            if analyzer.storyline:\n",
    "                # Display storyline visualization\n",
    "                storyline_img = analyzer.visualize_storyline()\n",
    "                if storyline_img:\n",
    "                    display(HTML(\"<h3>Character Network Visualization</h3>\"))\n",
    "                    display(Image.open(storyline_img))\n",
    "                \n",
    "                # Display characters\n",
    "                display(HTML(\"<h3>Characters</h3>\"))\n",
    "                for character, info in analyzer.storyline[\"characters\"].items():\n",
    "                    display(HTML(f\"<p><b>{character}</b>: mentioned {info['mentions']} times</p>\"))\n",
    "                \n",
    "                # Display themes\n",
    "                display(HTML(\"<h3>Themes</h3>\"))\n",
    "                for theme in analyzer.storyline[\"themes\"]:\n",
    "                    display(HTML(f\"<p>- {theme}</p>\"))\n",
    "                \n",
    "                # Display settings\n",
    "                if analyzer.storyline[\"settings\"]:\n",
    "                    display(HTML(\"<h3>Settings</h3>\"))\n",
    "                    for setting in analyzer.storyline[\"settings\"]:\n",
    "                        display(HTML(f\"<p>- {setting}</p>\"))\n",
    "                \n",
    "                # Display conflicts\n",
    "                if analyzer.storyline[\"conflicts\"]:\n",
    "                    display(HTML(\"<h3>Conflicts</h3>\"))\n",
    "                    for conflict in analyzer.storyline[\"conflicts\"]:\n",
    "                        display(HTML(f\"<p>- {conflict}</p>\"))\n",
    "            else:\n",
    "                display(HTML(\"<p>No storyline data available.</p>\"))\n",
    "    \n",
    "    def on_download_button_click(b):\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(\"Generating report...\")\n",
    "            \n",
    "            # Generate the report\n",
    "            report_path = analyzer.generate_report()\n",
    "            \n",
    "            if report_path:\n",
    "                print(\"Report generated successfully.\")\n",
    "                \n",
    "                # Create a download link\n",
    "                display(FileLink(report_path, result_html_prefix=\"Click here to download the report: \"))\n",
    "            else:\n",
    "                print(\"Error: Failed to generate report.\")\n",
    "    \n",
    "    def on_help_button_click(b):\n",
    "        with help_output:\n",
    "            clear_output()\n",
    "            display(HTML(\"\"\"\n",
    "            <h3>How to Use This Tool</h3>\n",
    "            <p><strong>1. File Format:</strong> Upload a JSON file containing narrative text.</p>\n",
    "            <p>The JSON file should have one of these structures:</p>\n",
    "            <pre>\n",
    "            {\n",
    "              \"text\": \"Your narrative text here...\"\n",
    "            }\n",
    "            </pre>\n",
    "            <p>OR</p>\n",
    "            <pre>\n",
    "            {\n",
    "              \"content\": \"Your narrative text here...\"\n",
    "            }\n",
    "            </pre>\n",
    "            <p>OR</p>\n",
    "            <pre>\n",
    "            {\n",
    "              \"title\": \"Story Title\",\n",
    "              \"text\": \"Your narrative text here...\"\n",
    "            }\n",
    "            </pre>\n",
    "            \n",
    "            <p><strong>2. Analysis:</strong> Click \"Analyze Text\" to process the narrative.</p>\n",
    "            <p><strong>3. Results:</strong> View the analysis in the tabs below.</p>\n",
    "            <p><strong>4. Report:</strong> Click \"Download Report\" to get a PDF report of the analysis.</p>\n",
    "            \n",
    "            <h4>Sample JSON</h4>\n",
    "            <pre>\n",
    "            {\n",
    "              \"title\": \"The Three Little Pigs\",\n",
    "              \"text\": \"Once upon a time, there were three little pigs. The first pig built a house of straw. The second pig built a house of sticks. The third pig built a house of bricks. One day, a big bad wolf came to the first pig's house. He huffed and puffed and blew the house down. The first pig ran to the second pig's house. The wolf followed and blew down the second house too. Both pigs ran to the third pig's house. The wolf tried to blow down the brick house, but he couldn't. He tried to enter through the chimney, but the third pig had a pot of boiling water. The wolf fell into the water and ran away. The three pigs lived happily ever after.\"\n",
    "            }\n",
    "            </pre>\n",
    "            \"\"\"))\n",
    "    \n",
    "    # Register callbacks\n",
    "    file_upload.observe(on_file_upload_change, names='value')\n",
    "    analyze_button.on_click(on_analyze_button_click)\n",
    "    download_button.on_click(on_download_button_click)\n",
    "    help_button.on_click(on_help_button_click)\n",
    "    \n",
    "    # Layout the widgets\n",
    "    upload_box = widgets.HBox([file_upload, analyze_button, download_button, help_button])\n",
    "    \n",
    "    # Display the GUI\n",
    "    display(header)\n",
    "    display(upload_box)\n",
    "    display(status_output)\n",
    "    display(help_output)\n",
    "    display(tab)\n",
    "    display(result_output)\n",
    "\n",
    "# Run the application\n",
    "create_narrative_analysis_gui()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77642e59-b375-42fd-a340-082484869b68",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This tool can be very useful for literary analysis, storytelling research, or educational purposes. Users can now upload JSON files containing narrative text and get detailed insights into the timeline, plotline, and storyline structures.\n",
    "\n",
    "If you want to further enhance the tool in the future, you might consider:\n",
    "\n",
    "Adding support for more file formats (TXT, DOCX, etc.)\n",
    "Implementing more advanced NLP techniques for better event extraction\n",
    "Adding sentiment analysis to track emotional arcs in narratives\n",
    "Creating more sophisticated visualizations\n",
    "Adding the ability to compare multiple narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec11d05-143e-4eb4-9a7c-33d7ec297011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
